# 3D Interior Designing App - Photo Sphere Capture

A React Native mobile application that captures 360Â° photo spheres using ultra-wide camera and device sensors, for AI-powered 3D interior reconstruction.

## Features

- ðŸ“· **Ultra-Wide Camera Access**: Automatically uses ultra-wide lens if available
- ðŸ§­ **Device Orientation Tracking**: Real-time azimuth, pitch, and roll detection
- ðŸŽ¯ **Guided Photo Capture**: Visual guides help align device for optimal photo sphere coverage
- ðŸ¤– **Auto-Capture Mode**: Automatically captures photos when device is properly aligned
- ðŸ“Š **Progress Tracking**: Visual feedback showing capture progress (16 photos)
- ðŸ”„ **Session Management**: Reset and restart capture sessions

## Architecture

```
Mobile [React Native App]
    â†“
Capture 16 Ultra-wide Photos
  - react-native-vision-camera
  - react-native-sensors
  - axios
  - @tanstack/react-query
    â†“
Upload to Backend (FastAPI / Node)
  - PostgreSQL
  - Redis
  - AWS S3
    â†“
[Stitching Service]
 - Python
  - OpenCV
  - Celery
    â†“
360Â° Equirectangular Panorama
    â†“
[AI Staging Engine]
  - NanoBanana API
    â†“
New Staged 360Â° Image
    â†“
[3D Reconstruction Engine]
  - WorldLabs API
    â†“
GLTF / 3D Scene Output
    â†“
[Storage]
  - S3 + CloudFront
    â†“
Mobile Viewer
  - react-three-fiber
  - GLTFLoader
  - Expo GL
```

## Prerequisites

- Node.js >= 18
- React Native development environment set up
  - For Android: Android Studio with SDK
  - For iOS: Xcode (macOS only)
- Physical device recommended (sensors work better on real devices)

## Installation

1. **Clone the repository**
```bash
git clone <repository-url>
cd InteriorDesigning3DApp
```

2. **Install dependencies**
```bash
npm install
```

3. **iOS Setup** (macOS only)
```bash
cd ios
pod install
cd ..
```

4. **Run the app**

For Android:
```bash
npm run android
```

For iOS:
```bash
npm run ios
```

## Photo Sphere Capture Guide

The app captures 16 photos in a systematic pattern to create a complete 360Â° sphere:

### Capture Pattern
- **4 rows** at different elevation angles: 60Â°, 20Â°, -20Â°, -60Â°
- **4 columns** at different azimuth angles: 0Â°, 90Â°, 180Â°, 270Â°

### How to Capture

1. **Auto Mode (Recommended)**:
   - The app automatically captures photos when you align your device
   - Follow the on-screen guidance to move your device
   - Green indicator shows when aligned
   - Photo is captured automatically after 0.5s of stable alignment

2. **Manual Mode**:
   - Tap "Manual" button to switch modes
   - Align device with target position
   - Tap capture button to take photo

3. **Best Practices**:
   - Stand in the center of the room
   - Keep steady when capturing
   - Ensure good lighting
   - Capture all 16 positions for best results

## Project Structure

```
InteriorDesigning3DApp/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ screens/
â”‚   â”‚   â””â”€â”€ CameraScreen.tsx       # Main camera interface
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ useCameraPermissions.ts # Camera permission management
â”‚   â”‚   â””â”€â”€ useDeviceOrientation.ts # Sensor-based orientation tracking
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â””â”€â”€ index.ts                # TypeScript type definitions
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ photoSphereHelper.ts    # Photo sphere calculation utilities
â”œâ”€â”€ android/                         # Android native code
â”œâ”€â”€ ios/                            # iOS native code
â””â”€â”€ App.tsx                         # App entry point
```

## Key Dependencies

- **react-native-vision-camera**: High-performance camera library with ultra-wide support
- **react-native-sensors**: Access to device accelerometer, gyroscope, and magnetometer
- **@tanstack/react-query**: Powerful data fetching and state management
- **axios**: HTTP client for API communication

## Permissions

### Android
- `CAMERA`: Capture photos
- `RECORD_AUDIO`: Required by vision-camera (not used for audio)
- `WRITE_EXTERNAL_STORAGE`: Save photos
- `READ_EXTERNAL_STORAGE`: Access saved photos

### iOS
- `NSCameraUsageDescription`: Capture photos
- `NSMicrophoneUsageDescription`: Required by vision-camera
- `NSMotionUsageDescription`: Track device orientation
- `NSPhotoLibraryUsageDescription`: Access photo library
- `NSPhotoLibraryAddUsageDescription`: Save photos

## Next Steps

1. **Backend Integration**: Connect to FastAPI/Node backend for photo upload
2. **Photo Stitching**: Implement or integrate with stitching service
3. **AI Staging**: Integration with NanoBanana API
4. **3D Reconstruction**: Integration with WorldLabs API
5. **3D Viewer**: Implement GLTF viewer with react-three-fiber

## Troubleshooting

### Camera not working
- Ensure permissions are granted in device settings
- Restart the app after granting permissions
- Try on a physical device (simulator has limited camera support)

### Sensor data inaccurate
- Calibrate device compass (figure-8 motion)
- Sensors work better on physical devices
- Ensure device is not near magnetic interference

### Build errors
- Run `npm install` again
- For iOS: `cd ios && pod install && cd ..`
- Clean build: 
  - Android: `cd android && ./gradlew clean && cd ..`
  - iOS: Clean build folder in Xcode

## Contributing

Contributions are welcome! Please follow the existing code style and add tests for new features.

## License

[Add your license here]
